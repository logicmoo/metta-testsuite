{"uid":"6ed4a53f177ca860","name":"hyperon-mettalog_sanity.idiomatic_negation_and_set_difference_he_805","historyId":"WHOLE-TESTS:WHOLE-TESTS#hyperon-mettalog_sanity.idiomatic_negation_and_set_difference_he_805","time":{"start":1732805667000,"stop":1732805676000,"duration":9000},"status":"passed","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"steps":[{"name":"<![CDATA[","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"<a href=\"file://reports/tests_output/baseline-compat/tests/baseline_compat/hyperon-mettalog_sanity/idiomatic_negation_and_set_difference_he_805.metta.html#WHOLE-TESTS.hyperon-mettalog_sanity.idiomatic_negation_and_set_difference_he_805\">Test Report</a>","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"Assertion: ./mettalog '--output=./reports/tests_output/baseline-compat/' --timeout=40 --html --repl=false  --test \"tests/baseline_compat/hyperon-mettalog_sanity/idiomatic_negation_and_set_difference_he_805.metta\" --halt=true","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"Expected: 7","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"Actual: 7","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"]]>","time":{},"steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":7,"attachmentsCount":0,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"resultFormat","value":"junit"},{"name":"suite","value":"WHOLE-TESTS"},{"name":"testClass","value":"WHOLE-TESTS"},{"name":"package","value":"WHOLE-TESTS"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[],"history":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":3,"unknown":0,"total":3},"items":[{"uid":"385f5cd0efc9c6b","reportUrl":"https://trueagi-io.github.io/metta-wam/ci/590//#testresult/385f5cd0efc9c6b","status":"passed","time":{"start":1732729689000,"stop":1732729698000,"duration":9000}},{"uid":"fdd5679f76fb2e0c","reportUrl":"https://trueagi-io.github.io/metta-wam/ci/584//#testresult/fdd5679f76fb2e0c","status":"passed","time":{"start":1732727831000,"stop":1732727841000,"duration":10000}}]},"tags":[]},"source":"6ed4a53f177ca860.json","parameterValues":[]}